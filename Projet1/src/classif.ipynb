{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1\n",
    "## Programmation d’une méthode de discrimination : Kppv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.io as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kppv(apprent, classe_origine, k, x):\n",
    "    clas = []\n",
    "    N1 = len(apprent[0])\n",
    "    N2 = len(x[0])\n",
    "     \n",
    "\n",
    "    # parcourir les individus à classer\n",
    "    for i in range (N2):\n",
    "        # position de l'individu\n",
    "        posIndividu = np.array(x[:,i])\n",
    "        # tableau de distance entre l'individu et tous l'apprentissage\n",
    "        dists_apprents = []\n",
    "        # calculer la distance avec tous les individus de l'apprentissage\n",
    "        for j in range (N1):\n",
    "            # position du voisin j\n",
    "            posAppr = np.array(apprent[:,j])\n",
    "            # classe du voisin j\n",
    "            classAppr = classe_origine[j]\n",
    "            # distance entre l'individu le voisin j\n",
    "            dist = np.linalg.norm(posIndividu - posAppr)\n",
    "            obj = [dist, classAppr]\n",
    "            # ajout de la distance et la classe au tableau\n",
    "            dists_apprents.append(obj)\n",
    "                    \n",
    "        # tri du tableau des distance\n",
    "        dists_apprents = sorted(dists_apprents, key=lambda o: o[0])\n",
    "        #print(dists_apprents)\n",
    "\n",
    "        # tableau des k plus proches voisins\n",
    "        kNearest = [o[1] for o in dists_apprents[:k]]\n",
    "        clas.append(max(kNearest, key = kNearest.count))\n",
    "        \n",
    "    return clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcTauxErreur(x, y):\n",
    "    return np.mean(x != y) * 100\n",
    "\n",
    "def affiche_classe(x, y, clas, title = \"Classification\", labels = [\"0\", \"1\", \"2\"]):\n",
    "    # afficher les résultats de la classification\n",
    "    scatter = plt.scatter(x, y, c = clas)\n",
    "    plt.title(title)\n",
    "    plt.legend(\n",
    "        handles=scatter.legend_elements()[0],\n",
    "        labels=labels\n",
    "        )\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def affiche_taux_erreur(k, tab1, tab2 = None, labels = [\"KNN\", \"Bayes\"], title = \"Taux d'erreur\"):\n",
    "    # afficher le graph des résultats de la classification bayesienne et knn\n",
    "    plt.plot(k, tab1, '-o')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"Taux d'erreur %\")\n",
    "    \n",
    "    if tab2 != None:\n",
    "        plt.plot(k, tab2, '-o')\n",
    "    plt.legend(labels)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = sp.loadmat(\"../data/p1_test.mat\")\n",
    "classes = [1]*50 + [2]*50 + [3]*50\n",
    "k = [1, 3, 5, 7, 13, 15]\n",
    "tauxErreur = []\n",
    "\n",
    "for i in k:\n",
    "    clas = kppv(Data[\"test\"], classes, i, Data[\"x\"])\n",
    "    affiche_classe(Data[\"x\"][0], Data[\"x\"][1], clas, \"Classification KNN pour k = \" + str(i))\n",
    "    error = calcTauxErreur(clas, Data[\"clasapp\"])\n",
    "    print(\"k = \", i, \"taux d'erreur = \", error , \"%\")\n",
    "    tauxErreur.append(error)\n",
    "\n",
    "\n",
    "affiche_taux_erreur(k, tauxErreur)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2\n",
    "## Comparaison des deux méthodes (param ́etriques et non param ́etriques)\n",
    "\n",
    "### 2.1 Influence de la taille de l’ensemble d’apprentissage : taille réduite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTIL\n",
    "def readExcel(fileName):\n",
    "    # load data\n",
    "    apprent = pd.read_excel('../data/' + fileName + '.xlsx', sheet_name='Ensemble Apprentissage')\n",
    "    x = pd.read_excel('../data/' + fileName + '.xlsx', sheet_name='Inconnu')\n",
    "\n",
    "    # remove column 0\n",
    "    apprent = apprent.drop(columns=['Unnamed: 0'])\n",
    "    x = x.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    # transpose\n",
    "    apprent = apprent.T\n",
    "    x = x.T\n",
    "\n",
    "    # oracle\n",
    "    oracle = x[2]\n",
    "\n",
    "    # remove column 2 \n",
    "    x = x.drop(columns=[2])\n",
    "\n",
    "    return apprent, x, oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "def naive_bayes(apprent, classe_origine, x):\n",
    "    # Create a Gaussian Classifier\n",
    "    model = GaussianNB()\n",
    "    # Train the model using the training sets\n",
    "    model.fit(apprent, classe_origine)\n",
    "    # Predict Output\n",
    "    return model.predict(x)\n",
    "\n",
    "# KNN\n",
    "def knn(apprent, classe_origine, k, x):\n",
    "    # Create KNN Classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Fit the classifier to the data\n",
    "    knn.fit(apprent, classe_origine)\n",
    "    # Predict Output\n",
    "    return knn.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0]*20 + [1]*20 + [2]*20\n",
    "k = [1, 3, 5, 7, 13, 15]\n",
    "p1_petit_apprent, p1_petit_x, p1_petit_oracle = readExcel(\"p1_petit\")\n",
    "\n",
    "# for KNN\n",
    "knnErrors = []\n",
    "for i in k:\n",
    "    res_knn = knn(p1_petit_apprent, classes, i, p1_petit_x)\n",
    "    affiche_classe(p1_petit_x[0], p1_petit_x[1], res_knn, \"Classification KNN pour k = \" + str(i))\n",
    "    error = calcTauxErreur(res_knn, p1_petit_oracle)\n",
    "    print(\"k = \", i, \"taux d'erreur = \", error , \"%\")\n",
    "    knnErrors.append(error)\n",
    "\n",
    "# for Bayes\n",
    "res_bayes = naive_bayes(p1_petit_apprent, classes, p1_petit_x)\n",
    "bayesErrors = [calcTauxErreur(res_bayes, p1_petit_oracle)]*len(k)\n",
    "\n",
    "affiche_taux_erreur(k, knnErrors, bayesErrors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Influence de la taille de l’ensemble d’apprentissage : taille importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0]*150 + [1]*150 + [2]*150\n",
    "k = [1, 3, 5, 7, 13, 15]\n",
    "\n",
    "p1_grand_apprent, p1_grand_x, p1_grand_oracle = readExcel(\"p1_grand\")\n",
    "\n",
    "# for KNN\n",
    "knnErrors = []\n",
    "for i in k:\n",
    "    res_knn = knn(p1_grand_apprent, classes, i, p1_grand_x)\n",
    "    affiche_classe(p1_grand_x[0], p1_grand_x[1], res_knn, \"Classification KNN pour k = \" + str(i))\n",
    "    error = calcTauxErreur(res_knn, p1_grand_oracle)\n",
    "    print(\"k = \", i, \"taux d'erreur = \", error , \"%\")\n",
    "    knnErrors.append(error)\n",
    "\n",
    "# for Bayes\n",
    "res_bayes = naive_bayes(p1_grand_apprent, classes, p1_grand_x)\n",
    "bayesErrors = [calcTauxErreur(res_bayes, p1_grand_oracle)]*len(k)\n",
    "\n",
    "affiche_taux_erreur(k, knnErrors, bayesErrors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Absence de professeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [1, 3, 5, 7, 13, 15]\n",
    "\n",
    "p1_kmean_apprent, p1_kmean_x, p1_kmean_oracle = readExcel(\"p1_Kmean\")\n",
    "classes = p1_kmean_apprent[2]\n",
    "p1_kmean_apprent = p1_kmean_apprent.drop(columns=[2])\n",
    "\n",
    "# for KNN\n",
    "knnErrors = []\n",
    "for i in k:\n",
    "    res_knn = knn(p1_kmean_apprent, classes, i, p1_kmean_x)\n",
    "    affiche_classe(p1_kmean_x[0], p1_kmean_x[1], res_knn, \"Classification KNN pour k = \" + str(i))\n",
    "    error = calcTauxErreur(res_knn, p1_kmean_oracle)\n",
    "    print(\"k = \", i, \"taux d'erreur = \", error , \"%\")\n",
    "    knnErrors.append(error)\n",
    "\n",
    "# for Bayes\n",
    "res_bayes = naive_bayes(p1_kmean_apprent, classes, p1_kmean_x)\n",
    "bayesErrors = [calcTauxErreur(res_bayes, p1_kmean_oracle)]*len(k)\n",
    "\n",
    "affiche_taux_erreur(k, knnErrors, bayesErrors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Distribution inconnue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [1, 3, 5, 7, 13, 15]\n",
    "\n",
    "p1_nonGaussien_apprent, p1_nonGaussien_x, p1_kmean_oracle = readExcel(\"p1_NonGaussien\")\n",
    "classes = p1_nonGaussien_apprent[2]\n",
    "p1_nonGaussien_apprent = p1_nonGaussien_apprent.drop(columns=[2])\n",
    "\n",
    "# for KNN\n",
    "knnErrors = []\n",
    "for i in k:\n",
    "    res_knn = knn(p1_nonGaussien_apprent, classes, i, p1_nonGaussien_x)\n",
    "    affiche_classe(p1_nonGaussien_x[0], p1_nonGaussien_x[1], res_knn, \"Classification KNN pour k = \" + str(i))\n",
    "    error = calcTauxErreur(res_knn, p1_kmean_oracle)\n",
    "    print(\"k = \", i, \"taux d'erreur = \", error , \"%\")\n",
    "    knnErrors.append(error)\n",
    "\n",
    "# for Bayes\n",
    "res_bayes = naive_bayes(p1_nonGaussien_apprent, classes, p1_nonGaussien_x)\n",
    "bayesErrors = [calcTauxErreur(res_bayes, p1_kmean_oracle)]*len(k)\n",
    "\n",
    "affiche_taux_erreur(k, knnErrors, bayesErrors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 3\n",
    "## Classification d'images\n",
    "### 3.1 Calcul des descripteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Jungle\", \"Plage\", \"Monuments\", \"Bus\", \"Dinosaures\", \"Eléphants\",\"Fleurs\", \"Chevaux\", \"Montagne\" , \"Plats\"]\n",
    "mesures = []\n",
    "descriptors = [\"WangSignaturesJCD\", \"WangSignaturesPHOG\", \"WangSignaturesCEDD\", \"WangSignaturesFCTH\", \"WangSignaturesFuzzyColorHistogr\"]\n",
    "\n",
    "for ensemble_mesure in descriptors:\n",
    "    X = (pd.read_excel('../data/WangSignatures.xls', ensemble_mesure, index_col = 0,header=None))\n",
    "    mesures.append([ensemble_mesure, X.values])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=np.zeros(1000,'int')\n",
    "for b in range(0,1000):\n",
    "    name= X.index[b] # something like '123.jpg'\n",
    "    lbl = int(int(name[0:-4])/100) # remove '.jpg' (4 last chars) and divide by 100\n",
    "    label[b]= lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Mise en place d'un système de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminate (descriptors, label):\n",
    "\n",
    "    mesures = pd.DataFrame()\n",
    "    for descriptor in descriptors:\n",
    "        X = (pd.read_excel('../data/WangSignatures.xls', descriptor, index_col = 0,header=None))\n",
    "        mesures = pd.concat([mesures, X], axis=1)\n",
    "\n",
    "\n",
    "    # split dataset (train and test)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(mesures.iloc[:, 1:], label, test_size=0.2, random_state=1, stratify=label)\n",
    "\n",
    "    # use KNN\n",
    "    k = [1, 3, 5, 7, 13, 15]\n",
    "    knnErrors = []\n",
    "    for i in k:\n",
    "        # create KNN classifier\n",
    "        knn = KNeighborsClassifier(n_neighbors=i)\n",
    "        # fit the classifier to the data\n",
    "        knn.fit(X_train, Y_train)\n",
    "        # predict\n",
    "        knn_res = knn.predict(X_test)\n",
    "\n",
    "        # calculate accuracy of class predictions\n",
    "        #print(\"k = \", i, \"taux d'erreur = \", calcTauxErreur(knn_res, Y_test) , \"%\")\n",
    "        knnErrors.append(calcTauxErreur(knn_res, Y_test))\n",
    "\n",
    "    # use Bayes\n",
    "    #Create a Gaussian Classifier\n",
    "    bayes = MultinomialNB()\n",
    "    # Train the model using the training sets\n",
    "    bayes.fit(X_train,Y_train)\n",
    "    # Predict \n",
    "    bayes_res = bayes.predict(X_test)\n",
    "    #print(\"bayes taux d'erreur = \", calcTauxErreur(bayes_res, Y_test) , \"%\")\n",
    "    bayesErrors = [calcTauxErreur(bayes_res, Y_test)]*len(k)\n",
    "\n",
    "    title = \"\" \n",
    "    for d in descriptors :\n",
    "        title +=  d + \" \"\n",
    "\n",
    "    affiche_taux_erreur(k, knnErrors, bayesErrors, title = \"taux d'erreur pour \" + title)\n",
    "\n",
    "    # confusion matrix\n",
    "    knn_cm = confusion_matrix(Y_test, knn_res)\n",
    "    # display confusion matrix for KNN in blue\n",
    "    cm_display = ConfusionMatrixDisplay(knn_cm).plot(cmap=plt.cm.Reds)\n",
    "        \n",
    "    plt.title(\"Matrice de confusion pour KNN avec \" + title)\n",
    "\n",
    "    bayes_cm = confusion_matrix(Y_test, bayes_res)\n",
    "    # display confusion matrix for Bayes\n",
    "    cm_display = ConfusionMatrixDisplay(bayes_cm).plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Matrice de confusion pour Bayes avec \" + title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminate with all descriptors one by one\n",
    "for descriptor in descriptors:\n",
    "    discriminate([descriptor], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminate with all descriptors together\n",
    "discriminate(descriptors, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find in the excel's first column the value \"imageNumber.jpg\"\n",
    "# and return the row number\n",
    "excel = pd.read_excel('../data/WangSignatures.xls', 'WangSignaturesJCD', index_col = 0,header=None)\n",
    "def findRowNumber(imageNumber):\n",
    "    for i in range(len(excel.index)):\n",
    "        if excel.index[i] == str(imageNumber) + \".jpg\":\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ let the user choose ############################\n",
    "def userChoiceDiscrimination() :\n",
    "    # user input an image number\n",
    "    imageNumber = int(input(\"Entrer un numéro d'image entre 0 et 999 : \"))\n",
    "    if imageNumber < 0 or imageNumber > 999:\n",
    "        print(\"Le numéro d'image doit être compris entre 0 et 999\")\n",
    "        return\n",
    "\n",
    "    # user input choice descriptor [\"JCD\", \"PHOG\", \"CEDD\", \"FCTH\", \"FuzzyColorHistogr\"]\n",
    "    descriptor = input(\"Entrer un descripteur parmi JCD, PHOG, CEDD, FCTH, FuzzyColorHistogr : \")\n",
    "    if descriptor not in [\"JCD\", \"PHOG\", \"CEDD\", \"FCTH\", \"FuzzyColorHistogr\"]:\n",
    "        print(\"Le descripteur doit être parmi JCD, PHOG, CEDD, FCTH, FuzzyColorHistogr\")\n",
    "        return\n",
    "\n",
    "    descriptor = \"WangSignatures\" + descriptor\n",
    "    mesure = pd.DataFrame()\n",
    "    X = (pd.read_excel('../data/WangSignatures.xls', descriptor, index_col = 0,header=None))\n",
    "    mesure = pd.concat([mesure, X], axis=1)\n",
    "\n",
    "    # user input choice model (KNN or Bayes)\n",
    "    model = input(\"Entrer un modèle parmi KNN ou Bayes : \")\n",
    "    if model not in [\"KNN\", \"Bayes\"]:\n",
    "        print(\"Le modèle doit être parmi KNN ou Bayes\")\n",
    "        return\n",
    "        # if KNN : user input k\n",
    "    if model == \"KNN\":\n",
    "        k = int(input(\"Entrer un entier k : \"))\n",
    "        if k < 1:\n",
    "            print(\"k doit être un entier positif\")\n",
    "            return\n",
    "        model = KNeighborsClassifier(n_neighbors=k)\n",
    "    else:\n",
    "        model = MultinomialNB()\n",
    "\n",
    "    # split dataset (train and test)\n",
    "    # With test_size 20% so 200 images / 1000\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(mesure.iloc[:, 1:], label, test_size=0.2, random_state=1, stratify=label)\n",
    "\n",
    "    # fit the classifier to the data\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # predict\n",
    "    res = model.predict(X_test)\n",
    "\n",
    "    # calculate accuracy of class predictions\n",
    "    print(\"taux d'erreur = \", calcTauxErreur(res, Y_test) , \"%\")\n",
    "\n",
    "    # find the imageNumber's row in the excel\n",
    "    rowNumber = findRowNumber(imageNumber)\n",
    "    print (\"rowNumber = \", rowNumber)\n",
    "\n",
    "    # predict the image class\n",
    "    imageClass = model.predict(mesure.iloc[rowNumber, 1:].values.reshape(1, -1))\n",
    "    predictionTitle = \"L'image \" + str(imageNumber) + \" est prédite comme appartenant à la classe \" + str(classes[imageClass[0]])\n",
    "    print(predictionTitle)\n",
    "\n",
    "    # display the image\n",
    "    image = mpimg.imread(\"../data/Wang/\" + str(imageNumber) + \".jpg\")\n",
    "    plt.title(predictionTitle)\n",
    "    plt.imshow(image)\n",
    "\n",
    "\n",
    "print(\"Choix de l'utilisateur ex : '0 JCD KNN 3' ou '12 CEDD Bayes', '999 FuzzyColorHistogr KNN 5'\")\n",
    "userChoiceDiscrimination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4428cbe1ba9314b3551257500664b995dcc328d303584ff4cad6f1a703111ed9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
