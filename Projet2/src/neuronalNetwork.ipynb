{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Développement d'un perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import randint, choice\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Mise en place d'un perceptron simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la variable w contient les poids synaptiques du neurone (vecteur à 3 lignes, la première ligne correspond à au seuil)\n",
    "# la variable x contient \n",
    "def perceptron_simple(x, w, active):\n",
    "    x0 = np.concatenate(([1], x)) # x0 = 1\n",
    "    v = np.sum(np.multiply(x0, w))\n",
    "\n",
    "    if active == 0:\n",
    "        return np.sign(v)\n",
    "    elif active == 1:\n",
    "        return np.tanh(v)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILS\n",
    "\n",
    "# Affichage des entrées sous forme de graphique\n",
    "def getClass(p):\n",
    "  if p >= 0:\n",
    "    return 'g'\n",
    "  else:\n",
    "    return 'r'\n",
    "\n",
    "# Affichage des entrées sous forme de graphique avec plusieurs classes\n",
    "def getClass(p, classes = [-1, 0, 1, 2, 3 ]):\n",
    "  if p == classes[0]:\n",
    "    return 'g'\n",
    "  elif p == classes[1]:\n",
    "    return 'b'\n",
    "  elif p == classes[2]:\n",
    "    return 'r'\n",
    "  elif p == classes[3]:\n",
    "    return 'y'\n",
    "  elif p == classes[4]:\n",
    "    return 'c'\n",
    "\n",
    "def initGrid(xmin, xmax, ymin, ymax):\n",
    "  x = np.linspace(xmin,xmax,50)\n",
    "  plt.xlim(xmin,xmax)\n",
    "  plt.ylim(ymin,ymax)\n",
    "  plt.grid()\n",
    "\n",
    "def putPoints(X, YD, classes = [-1, 0, 1, 2, 3 ]):\n",
    "  for p in range(len(YD)):\n",
    "    plt.plot(X[p][0], X[p][1], getClass(YD[p], classes) + 'o')\n",
    "\n",
    "def putLine(xmin, xmax, w):\n",
    "  x = np.linspace(xmin,xmax,50)\n",
    "  y = (w[0] + x*w[1]) / (-w[2])\n",
    "  plt.plot(x, y)\n",
    "\n",
    "def putMultipleLines(xmin, xmax, multi_w):\n",
    "  x = np.linspace(xmin,xmax,50)\n",
    "  for i in range(len(multi_w)):\n",
    "    y = (multi_w[i][0] + x*multi_w[i][1]) / (-multi_w[i][2])\n",
    "    plt.plot(x, y)\n",
    "\n",
    "def showGrid(title = ''):\n",
    "  plt.title(title)\n",
    "  plt.show()  \n",
    "\n",
    "\n",
    "# afficher la droite séparatrice associée aux poids du neurone\n",
    "def droite_separatrice(X, YD, w, xmin = -2, xmax = 2, ymin = -2, ymax = 2, titre = '', classes = [-1, 0, 1, 2, 3 ]):\n",
    "\n",
    "  initGrid(xmin, xmax, ymin, ymax)\n",
    "  putPoints(X, YD, classes)\n",
    "  putLine(xmin, xmax, w)\n",
    "  showGrid(titre)\n",
    "\n",
    "def droite_separatrice_multiple(X, YD, multi_w, xmin = -2, xmax = 2, ymin = -2, ymax = 2, titre = '', classes = [-1, 0, 1, 2, 3 ]):\n",
    "\n",
    "  initGrid(xmin, xmax, ymin, ymax)\n",
    "  putPoints(X, YD, classes)\n",
    "  putMultipleLines(xmin, xmax, multi_w)\n",
    "  showGrid(titre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test du perceptron avec l'exemple du OU logique vu en cours (phi(x) = sign(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test perceptron simple sur la porte OU\n",
    "\n",
    "# poids\n",
    "w = np.array([-0.5, 1, 1])\n",
    "\n",
    "# entrées\n",
    "x = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "\n",
    "# sortie\n",
    "res = []\n",
    "for i in range(4) :\n",
    "  res.append(perceptron_simple(x[i], w, 0))\n",
    "\n",
    "droite_separatrice(x, res, w, -0.5, 1.5, -0.5, 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Etude de l'apprentissage\n",
    "#### 1.2.1 Programmation apprentissage Widrow-hoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x contient l'ensemble d'apprentissage (matrice à 2 lignes et n colonnes).\n",
    "# yd[i] indique la réponse désirée pour chaque élément x[:,i]. yd est un vecteur à 1 ligne et n colonnes de valeurs -1 ou +1 (classification à 2 classes).\n",
    "# epoch le nomble d'itérations sur l'ensemble d'apprentissage.\n",
    "# batch_size le nombre d'individus de l'ensemble d'apprentissage traités avant mise à jour des poids \n",
    "def apprentissage_widrow(x, yd, epoch, batch_size) :\n",
    "    w = np.random.rand(len(x[0]) + 1) * 2 - 1 # w contient les poids synaptiques du neurone après apprentissage (vecteur à 3 lignes, dont la première ligne correspond à au seuil)\n",
    "    erreur = np.zeros((epoch)) # l'erreur cumulée calculée pour passage complet sur l'ensemble d'apprentissage (somme (yd(i) - y(i))²). La variable erreur est donc un vecteur de taille égale au nombre d'itération.\n",
    "    alpha = 0.1 # le coefficient d'apprentissage\n",
    "\n",
    "    droite_separatrice(x, yd, w, -5, 5, -5, 5, 'Droite séparatrice initiale')\n",
    "\n",
    "    for i in range(epoch):\n",
    "        tmp_w = w\n",
    "        erreur[i] = 0\n",
    "        for j in range(len(x)):\n",
    "            y = perceptron_simple(x[j], w, 1)\n",
    "            erreur[i] += (yd[j] - y) ** 2\n",
    "            tmp_w += alpha * (yd[j] - y) * np.concatenate(([1], x[j]))\n",
    "\n",
    "            # mise à jour des poids à chaque batch_size\n",
    "            if (j % batch_size) == 0:\n",
    "                w = tmp_w\n",
    "        \n",
    "        # affichage de la droite séparatrice associée aux poids du neurone\n",
    "        titre = 'Itération ' + str(i+1) + '\\nerreur cumulée = ' + str(erreur[i])\n",
    "        droite_separatrice(x, yd, w, -5, 5, -5, 5, titre)\n",
    "\n",
    "        if erreur[i] == 0:\n",
    "            break\n",
    "\n",
    "    return w, erreur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test pour le OU\n",
    "x = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "yd = np.array([-1, 1, 1, 1])\n",
    "\n",
    "w, erreur = apprentissage_widrow(x, yd, 20, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Test 1 simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data p2_d1.txt\n",
    "data = np.loadtxt('../data/p2_d1.txt')\n",
    "x = list(map(list,zip(data[0],data[1])))\n",
    "yd = [-1]*25 + [1]*25\n",
    "\n",
    "# application de l'algorithme de Widrow-Hoff\n",
    "w, erreur = apprentissage_widrow(x, yd, 20, 5)\n",
    "print(\"w : \", w, \"\\nerreur : \", erreur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data p2_d2.txt\n",
    "data = np.loadtxt('../data/p2_d2.txt')\n",
    "x = list(map(list,zip(data[0],data[1])))\n",
    "yd = [-1]*25 + [1]*25\n",
    "\n",
    "# application de l'algorithme de Widrow-Hoff\n",
    "w, erreur = apprentissage_widrow(x, yd, 15, 5)\n",
    "print(\"w : \", w, \"\\nerreur : \", erreur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Perceptron multicouches\n",
    "### 1.3.1 Mise en place d’un perceptron multicouche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def perceptron(x, w, activation_function): # comme perceptron_simple mais avec une fonction d'activation en paramètre\n",
    "    return activation_function(np.dot(w, np.concatenate(([1], x))))\n",
    "\n",
    "def multiperceptron(x,w1,w2):\n",
    "    y1 = perceptron(x, w1[:, 0], sigmoid)\n",
    "    y2 = perceptron(x, w1[:, 1], sigmoid)\n",
    "\n",
    "    res_couche_cachee = np.array([y1, y2])\n",
    "    y = perceptron(res_couche_cachee, w2, sigmoid)\n",
    "    return (y1, y2, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparer le résultat ”informatique” avec la sortie attendue calculée sur ”le papier”**\n",
    "\n",
    "Sur papier:\n",
    "\n",
    "1er  neurone: (1 * (-0.5))  + (1 * 2) + (1 * (-1)) = 0.5 => sigmoid(0.5) = 0.6224593312018546\n",
    "2ème neurone: (1 * 0.5) + (1 * 0.5) + (1 * 1) = 2 => sigmoid(2) = 0.8807970779778823\n",
    "\n",
    "3ème neurone: (1 * 2) + (-1 * 0.6224593312018546) + (1 * 0.8807970779778823) = 2.258338 => sigmoid(2.258338) = 0.9053673095402572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test avec l'exepmle du cours\n",
    "x  = np.array([1, 1])\n",
    "w1 = np.array([[-0.5, 0.5], [2.0, 0.5], [-1.0, 1.0]])\n",
    "w2 = np.array([2.0, -1.0, 1.0])\n",
    "\n",
    "print(multiperceptron(x, w1, w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Programmation apprentissage multicouches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def multiperceptron_widrow(x,yd,Epoch,Batch_size):\n",
    "\n",
    "    # initialisation des poids\n",
    "    w1 = np.random.rand(len(x[0]) + 1, 2) * 2 - 1\n",
    "    w2 = np.random.rand(3) * 2 - 1\n",
    "    erreur = np.zeros((Epoch))\n",
    "    alpha = 0.5\n",
    "\n",
    "    # affichage de la droite séparatrice associée aux poids du neurone\n",
    "    titre = 'droite séparatrice initiale'\n",
    "    # créer le tableau des droites séparatrices à afficher avec les poids\n",
    "    multi_w = np.array([w1[:, 0], w1[:, 1], w2])\n",
    "    # affichage de toutes les droites séparatrices avec droite_separatrice_multiple\n",
    "    droite_separatrice_multiple(x, yd, multi_w, -5, 5, -5, 5, titre)\n",
    "\n",
    "    for i in range(Epoch):\n",
    "        tmp_w1 = w1\n",
    "        tmp_w2 = w2\n",
    "        erreur[i] = 0\n",
    "        for j in range(len(x)):\n",
    "\n",
    "            individu = x[j]\n",
    "            (y1, y2, y) = multiperceptron(individu, w1, w2)\n",
    "\n",
    "            erreur[i] += (yd[j] - y) ** 2\n",
    "\n",
    "            rf = (yd[j] - y) * derive(y)\n",
    "            r11 = rf * w2[1] * derive(y1)\n",
    "            r12 = rf * w2[2] * derive(y2)\n",
    "\n",
    "\n",
    "            tmp_w1[:, 0] += alpha * r11 * np.concatenate(([1], individu))\n",
    "            tmp_w1[:, 1] += alpha * r12 * np.concatenate(([1], individu))\n",
    "\n",
    "            tmp_w2 += alpha * rf * np.array([1, y1, y2])\n",
    "\n",
    "\n",
    "            if (j % Batch_size) == 0:\n",
    "                w1 = tmp_w1\n",
    "                w2 = tmp_w2\n",
    "        \n",
    "        # on arrête l'apprentissage si l'erreur est inférieure à 0.001 (on arrivera jamais à 0 car on a une fonction d'activation sigmoid)\n",
    "        if erreur[i] < 0.001:\n",
    "            break\n",
    "\n",
    "    # affichage de la droite séparatrice associée aux poids du neurone\n",
    "    titre = 'Itération ' + str(i+1) + '\\nerreur cumulée = ' + str(erreur[i])\n",
    "    # créer le tableau des droites séparatrices à afficher avec les poids\n",
    "    multi_w = np.array([w1[:, 0], w1[:, 1], w2])\n",
    "    # affichage de toutes les droites séparatrices avec droite_separatrice_multiple\n",
    "    droite_separatrice_multiple(x, yd, multi_w, -5, 5, -5, 5, titre)\n",
    "\n",
    "    return w1, w2, erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test avec le XOR  \n",
    "x = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "yd = np.array([0, 1, 1, 0])\n",
    "\n",
    "w1, w2, erreur = multiperceptron_widrow(x, yd, 10000, 2)\n",
    "print(\"w1 : \", w1, \"\\nw2 : \", w2, \"\\nerreur : \", erreur)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep et Full-connected : discrimination d'une image\n",
    "### Approche basée Descripteurs (basée modèle)\n",
    "#### Calcul des descripteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Jungle\", \"Plage\", \"Monuments\", \"Bus\", \"Dinosaures\", \"Eléphants\",\"Fleurs\", \"Chevaux\", \"Montagne\" , \"Plats\"]\n",
    "Mesures = []\n",
    "descriptors = [\"WangSignaturesJCD\", \"WangSignaturesPHOG\", \"WangSignaturesCEDD\", \"WangSignaturesFCTH\", \"WangSignaturesFuzzyColorHistogr\"]\n",
    "\n",
    "for descritor in descriptors:\n",
    "    X = (pd.read_excel('../data/WangSignatures.xls', descritor, index_col = 0,header=None))\n",
    "    \n",
    "    # le premier descripteur \n",
    "    if (descritor == descriptors[0]):\n",
    "        Mesures = X.values\n",
    "    else:\n",
    "        Mesures = np.concatenate((Mesures, X.values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=np.zeros(1000,'int')\n",
    "for b in range(0,1000):\n",
    "    name= X.index[b] # something like '123.jpg'\n",
    "    lbl = int(int(name[0:-4])/100) # remove '.jpg' (4 last chars) and divide by 100\n",
    "    label[b]= lbl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mise en place d’un système de discrimination basée structure Full-Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = np.array([np.eye(10)[label[i]] for i in range(len(label))])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Target, test_size=0.2, random_state=1, stratify=label)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=1_000, batch_size=32,validation_split=0.1, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num = int(input(\"Entrer le numéro de l'image à tester parmi les images de test (0 à \" + str(len(X_test)) + \") : \"))\n",
    "\n",
    "for rep in range (0,10):\n",
    "    # tirer au hasard une image de test\n",
    "    num = np.random.randint(0, len(X_test))\n",
    "    img_name = X_test.index[num]\n",
    "    img = plt.imread(\"../data/Wang/\" + img_name)\n",
    "\n",
    "    # show image each time\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    classe = int(X_test.index[num].split(\".\")[0]) // 100\n",
    "    pred = model.predict(X_test.iloc[num].values.reshape(1, -1), verbose=0)\n",
    "    classe_pred = np.argmax(pred)\n",
    "    percentage = round(pred[0][classe_pred]*100, 2)\n",
    "\n",
    "    print(f\"L'image {img_name} est de la classe {classe} : {classes[classe]}\")\n",
    "    print(f\"Le modèle prédit avec {percentage}% de certitude que l'image est de la classe {classe_pred} : {classes[classe_pred]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4428cbe1ba9314b3551257500664b995dcc328d303584ff4cad6f1a703111ed9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
