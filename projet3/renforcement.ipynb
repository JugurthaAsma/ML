{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5HGSGxhnEfS"
      },
      "source": [
        "# 1. Développement d'un jeu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "16u0v0mvnEfU"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6bQNPZzonEfV"
      },
      "outputs": [],
      "source": [
        "# configuration\n",
        "GAMMA = 0.96\n",
        "ALPHA = 0.81"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehrDGUS-pwUG"
      },
      "source": [
        "##### Créer une fonction qui permet de simuler le plateau en positionnant notamment les différents éléments (case départ, fin, dragons)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "dWZoG4tanEfW"
      },
      "outputs": [],
      "source": [
        "#for the space\n",
        "\"\"\"\n",
        "by default the default space is used\n",
        "the space is a 2D array 4 * 4 of characters\n",
        "the characters are: \n",
        "    'S' : the starting point\n",
        "    '_' : empty space\n",
        "    'J' : the goal\n",
        "    'D' : a dragon\n",
        "the default space is:\n",
        "    S___\n",
        "    D_D_ \n",
        "    ___D\n",
        "    _D_J\n",
        "\"\"\"\n",
        "\n",
        "# the default space\n",
        "default_space = [\n",
        "        ['S', '_', '_', '_'],\n",
        "        ['D', '_', 'D', '_'],\n",
        "        ['_', '_', '_', 'D'],\n",
        "        ['_', 'D', '_', 'J']\n",
        "    ]\n",
        "\n",
        "def get_default_space():\n",
        "    return default_space\n",
        "\n",
        "# a random space with number of lines and columns and a number of dragons\n",
        "def get_random_space(lines, columns, dragons):\n",
        "    space = []\n",
        "    for l in range(lines):\n",
        "        space.append([])\n",
        "        for c in range(columns):\n",
        "            space[l].append('_')\n",
        "\n",
        "    space[0][0] = 'S'\n",
        "    space[lines-1][columns-1] = 'J'\n",
        "    \n",
        "    i = 0\n",
        "    while i < dragons:\n",
        "        l = random.randint(0, lines-1)\n",
        "        c = random.randint(0, columns-1)\n",
        "        if space[l][c] == '_':\n",
        "            space[l][c] = 'D'\n",
        "            i += 1\n",
        "        else:\n",
        "            i -= 1\n",
        "\n",
        "    return space\n",
        "\n",
        "# pretty print the space\n",
        "def print_space(space):\n",
        "    for l in space:\n",
        "        for c in l:\n",
        "            print(c, end='| ')\n",
        "        \n",
        "        print()\n",
        "\n",
        "# get the size of the lines\n",
        "def get_lines_size(space):\n",
        "    return len(space)\n",
        "\n",
        "# get the size of the columns\n",
        "def get_columns_size(space):\n",
        "    return len(space[0])\n",
        "\n",
        "# get the size of the space\n",
        "def get_size(space):\n",
        "    return get_lines_size(space) * get_columns_size(space)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-eVBWhkOnEfX"
      },
      "outputs": [],
      "source": [
        "# a static class for the rewards\n",
        "class Rewards:\n",
        "    # the rewards for each character\n",
        "    rewards = {\n",
        "        'S': 0,\n",
        "        '_': 0,\n",
        "        'J': 1,\n",
        "        'D': -1\n",
        "    }\n",
        "\n",
        "    # a method to get the reward of a character\n",
        "    def get_reward(character):\n",
        "        return Rewards.rewards.get(character)\n",
        "\n",
        "    # a method to set the reward \n",
        "    def set_rewards(rewards):\n",
        "        Rewards.rewards = rewards\n",
        "\n",
        "    # a method to set the reward of a character\n",
        "    def set_reward(character, reward):\n",
        "        Rewards.rewards[character] = reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qL0SIBRpwUI"
      },
      "source": [
        "##### Créer une fonction qui permet de simuler l'interaction entre l'agent et son environnement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "amIQUyAKnEfX"
      },
      "outputs": [],
      "source": [
        "# a static class for the Directions\n",
        "class Directions:\n",
        "    # the directions\n",
        "    directions = [\"HAUT\", \"DROITE\", \"BAS\", \"GAUCHE\"]\n",
        "\n",
        "    # a method to get the size of the directions\n",
        "    def get_size():\n",
        "        return len(Directions.directions)\n",
        "\n",
        "    # a method to get the index of a direction\n",
        "    def get_index(direction):\n",
        "        return Directions.directions.index(direction)\n",
        "\n",
        "    # a method to get a random direction\n",
        "    def get_random_direction():\n",
        "        return random.choice(Directions.directions)\n",
        "\n",
        "    # a method to get the direction that maximizes the Q value\n",
        "    def get_max_direction(mat_q, state):\n",
        "        return Directions.directions[np.argmax(mat_q[state])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "emfLzRnwnEfY"
      },
      "outputs": [],
      "source": [
        "def isFin (space, position, verbose = False):\n",
        "    (l,c) = position\n",
        "\n",
        "    # if the player is at the goal, back to the starting point\n",
        "    if(space[l][c]== 'J'):\n",
        "        # print in green win\n",
        "        if verbose:\n",
        "            print(\"\\033[92m\" + \n",
        "            \"***********************************************************************************************************************************************************\\n\" +\n",
        "            \"********************************************************************** YOU WIN ****************************************************************************\\n\" +\n",
        "            \"***********************************************************************************************************************************************************\\n\" +\n",
        "            \"\\033[0m\")\n",
        "        return True, (0,0)\n",
        "\n",
        "    # # if the player ecnounters a dragon, back to the starting point\n",
        "    if(space[l][c]== 'D'):\n",
        "        # print in red loose\n",
        "        if verbose:\n",
        "            print(\"\\033[91m\" +\n",
        "            \"********************************************************************** YOU LOOSE ***************************************************************************\\n\" +\n",
        "            \"\\033[0m\")\n",
        "        return True, (0,0)\n",
        "\n",
        "    return False, position\n",
        "\n",
        "# a method to apply an action to the player\n",
        "def applicaion_action(action, position, space, verbose = False):\n",
        "\n",
        "    (l, c) = position\n",
        "    nextPos = position\n",
        "\n",
        "    if action == \"HAUT\":\n",
        "        nextPos = (l-1,c)\n",
        "    elif action == \"DROITE\":\n",
        "        nextPos = (l,c+1)\n",
        "    elif action == \"BAS\":\n",
        "        nextPos = (l+1,c);\n",
        "    elif action == \"GAUCHE\":\n",
        "        nextPos = (l,c-1);\n",
        "\n",
        "    # check if the next position is in the space\n",
        "    if (nextPos[0] < len(space) and nextPos[1] < len(space) and nextPos[0] >=0 and nextPos[1] >=0 ):\n",
        "        position = nextPos\n",
        "        \n",
        "    # get the current case in the space\n",
        "    case = space[position[0]][position[1]]\n",
        "    # set the reward\n",
        "    reward = Rewards.get_reward(case)\n",
        "\n",
        "    # check if the player is at the goal\n",
        "    fin, position = isFin(space, position, verbose)\n",
        "\n",
        "    return [position, reward, fin]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3CB8YzfpwUK"
      },
      "source": [
        "### Donner quelques éléments de commentaire sur la mise en place de l'environnement de jeux\n",
        "\n",
        "##### 1) Le plateau\n",
        "\n",
        "Pour créer un environnement de jeux, nous avons d'abord créé une la variable ***default_space*** qui est un tableau 2 dimensions **(4*4)** de charactères qui representent les cases du plateau de jeu proposé. Les cases sont représentées par les caractères suivants:\n",
        "\n",
        "*   **\"_\"** représente une case vide\n",
        "*   **\"D\"** représente une case avec un dragon\n",
        "*   **\"S\"** représente la case de départ\n",
        "*   **\"J\"** représente la case d'arrivée (JAIL)\n",
        "\n",
        "\n",
        "Nous avons aussi créé une fonction ***get_random_space*** qui permet de générer un plateau de jeu aléatoire en precisant le nombre de lignes, de colonnes etle nombre de dragons à placer sur le plateau.\n",
        "\n",
        "Nous avons aussi créé une fonction ***print_space*** qui permet d'afficher le plateau de jeu.\n",
        "\n",
        "##### 2) L'interaction\n",
        "\n",
        "Avec la function ***application_action*** nous créons une nouvelle position ***nextPos*** en fonction de l'***action***, et nous verifions si la nouvelle position est valide ou non. \n",
        "\n",
        "Si la nouvelle position est valide, nous mettons à jour la position de l'agent et nous recupérons la récompense associée à cette nouvelle position.\n",
        "\n",
        "Si la nouvelle position n'est pas valide, nous ne mettons pas à jour la position de l'agent et nous recupérons la récompense associée à la position actuelle.\n",
        "\n",
        "Puis nous verifions si la partie est terminée ou non (si l'agent est arrivé à la case d'arrivée ou s'il tombé sur un dragon), si la partie est terminée, nous réinitialisons la position de l'agent à la case de départ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDxUSIRynEfZ"
      },
      "source": [
        "# 2. Développement du Q-learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Ug3WW4dUpwUL"
      },
      "outputs": [],
      "source": [
        "# for the Q matrix\n",
        "# init the Q matrix with zeros and the size of the space and the directions length\n",
        "def init_mat_q(space):\n",
        "    return np.zeros((get_lines_size(space), get_columns_size(space), Directions.get_size()))\n",
        "\n",
        "# get the Q value of a state and a direction\n",
        "def get_q_value(mat_q, state, direction):\n",
        "    return mat_q[state][Directions.get_index(direction)]\n",
        "\n",
        "# update the Q matrix\n",
        "# according to state, action, reward, next_state, ALPHA and GAMMA\n",
        "def update_mat_q(mat_q, state, action, reward, next_state):\n",
        "    mat_q[state][Directions.get_index(action)] += ALPHA * (reward + GAMMA * np.max(mat_q[next_state]) - mat_q[state][Directions.get_index(action)])\n",
        "    return mat_q\n",
        "\n",
        "# pretty print the space\n",
        "def print_mat_q(mat_q, space):\n",
        "    def get_best_direction(l, c):\n",
        "        return Directions.directions[np.argmax(mat_q[l][c])]\n",
        "\n",
        "    for l in range(get_lines_size(space)):\n",
        "        for c in range(get_columns_size(space)):\n",
        "            case      = space[l][c]\n",
        "            direction = get_best_direction(l, c)\n",
        "            q_value   = str(round(get_q_value(mat_q, (l, c), direction), 2)).ljust(6)\n",
        "\n",
        "            content = case + \" (\" + q_value + \") \" + direction\n",
        "            print(content.ljust(20), end='| ')\n",
        "        print(\"\\n_______________________________________________________________________________________\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "TIz5A3zznEfZ"
      },
      "outputs": [],
      "source": [
        "# a class for the game\n",
        "class Game:\n",
        "    # constructor that takes :\n",
        "    # number of episodes : 10000 by default\n",
        "    # number of steps : 100 by default\n",
        "    # is_random_space : False by default\n",
        "    # a Q matrix : initialized with zeros (with the size of the space and the number of directions)\n",
        "    def __init__(self, episodes = 10000, steps = 100, is_random_space = False, mat_q = None):\n",
        "        self.episodes = episodes\n",
        "        self.steps = steps\n",
        "        # the space\n",
        "        if is_random_space:\n",
        "            self.space = get_random_space(4, 4, 3)\n",
        "        else:\n",
        "            self.space = get_default_space()\n",
        "        \n",
        "        # the Q matrix \n",
        "        if mat_q is None:\n",
        "            self.mat_q = init_mat_q(self.space)\n",
        "\n",
        "    # a method to choose an action with the epsilon greedy policy\n",
        "    def choose_action(self, state, epsilon, mat_q):\n",
        "        if random.random() < epsilon:\n",
        "            return Directions.get_random_direction()\n",
        "        else:\n",
        "            return Directions.get_max_direction(mat_q, state)\n",
        "\n",
        "    # a method to play one step (with mat_q, state, epsilon)\n",
        "    def oneStep(self, mat_q, state, epsilon, verbose):\n",
        "        # choose an action\n",
        "        action = self.choose_action(state, epsilon, mat_q)\n",
        "        if verbose:\n",
        "            print(action, end=', ')\n",
        "        # apply the action\n",
        "        new_state, reward, fin = applicaion_action(action, state, self.space)\n",
        "        # update the Q matrix\n",
        "        new_q = update_mat_q(mat_q, state, action, reward, new_state)\n",
        "        return new_q, new_state, fin\n",
        "\n",
        "    # a method to apply the algorithm \n",
        "    def apply_algorithm(self):\n",
        "        total_steps = 0\n",
        "        # apply the algorithm \n",
        "        for episode in range(self.episodes):\n",
        "            # reset the position\n",
        "            position = (0, 0)\n",
        "            # calculate the epsilon\n",
        "            epsilon = self.episodes / (self.episodes + episode)\n",
        "            #print(\"epsilon : \", epsilon)\n",
        "\n",
        "            # play the game\n",
        "            for step in range(1, self.steps):\n",
        "                # play one step\n",
        "                self.mat_q, position, fin = self.oneStep(self.mat_q, position, epsilon, False)\n",
        "                # if the game is finished\n",
        "                if fin:\n",
        "                    total_steps += step\n",
        "                    break\n",
        "\n",
        "        print(\"total steps : \", total_steps)\n",
        "        print(\"average steps : \", total_steps / self.episodes)\n",
        "\n",
        "    # a method to play the game\n",
        "    def play(self):\n",
        "        # reset the position\n",
        "        position = (0, 0)\n",
        "        # play the game\n",
        "        for step in range(1, self.steps):\n",
        "            # play one step\n",
        "            self.mat_q, position, fin = self.oneStep(self.mat_q, position, 0, True)\n",
        "            # if the game is finished\n",
        "            if fin:\n",
        "                break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWZfAABqnEfa",
        "outputId": "ebf9ad2d-fd0a-4b43-c17e-e7ba0f7631c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total steps :  58463\n",
            "average steps :  5.8463\n"
          ]
        }
      ],
      "source": [
        "# PLAY\n",
        "game = Game()\n",
        "game.apply_algorithm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncr7KZt_jiZ1"
      },
      "source": [
        "### Donner des éléments de commentaire sur la stratégie que vous avez utilisée pour développer l'algorithme de Q-Learning.\n",
        "\n",
        "##### 1) La matrice Q\n",
        "\n",
        "Nous avons :\n",
        "*   Une function ***init_mat_q*** qui prend en paramètre le plateau de jeu et elle retourne la matrice Q ***(nombre de ligne * nombre de ligne * Nombre de directions)*** initialisée à 0.\n",
        "*   Une function ***update_mat_q*** qui prend en paramètre la matrice Q, la position actuelle, la position suivante, l'action, la récompense et met à jour la matrice Q à la position actuelle et et pour la direction de l'action en utilisant la formule du cours.\n",
        "\n",
        "\n",
        "##### 2) L'algorithme Q-learning\n",
        "\n",
        "Nous avons une class ***Game***, son constructeur prend en paramètre :\n",
        "*   Le nombre de parties à jouer (10000 par défaut)\n",
        "*   Le nombre de coups par partie (100 par défaut)\n",
        "*   Un booléen ***is_random_space*** (False par défaut) qui permet de choisir si on veut un plateau de jeu aléatoire ou celui proposé par défaut\n",
        "*   Une matrice Q (None par défaut) qui permet de choisir si on veut utiliser une matrice Q déjà existante ou une nouvelle matrice Q qu'on va générer à partir du plateau de jeu\n",
        "\n",
        "La stratégie utilisée est l'***epsilon-greedy***, on choisit une action aléatoire avec une probabilité ***epsilon***, sinon on choisit l'action qui maximise la récompense.\n",
        "\n",
        "Dans la boucle pricipale de l'algorithme, l'epsilon est une fraction (nombre de parties  à jouer / nombre de parties  à jouer + nombre de parties jouées), donc au fur et à mesure que le nombre de parties jouées augmente, l'epsilon diminue.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0yLMr9AjiZ2",
        "outputId": "d5728279-7196-445d-8fd0-98e33e1f8105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[3.603157   3.75328854 2.603157   3.603157  ]\n",
            "  [3.75328854 3.603157   3.90967556 3.603157  ]\n",
            "  [3.603157   3.45903072 2.603157   3.75328854]\n",
            "  [3.45903072 3.45903072 3.32066949 3.603157  ]]\n",
            "\n",
            " [[0.         0.         0.         0.        ]\n",
            "  [3.75328854 2.603157   4.07257871 2.603157  ]\n",
            "  [0.         0.         0.         0.        ]\n",
            "  [3.45903072 3.32066949 2.603157   2.60315684]]\n",
            "\n",
            " [[2.603157   4.07257871 3.75328854 3.90967556]\n",
            "  [3.90967556 4.24226949 2.603157   3.90967556]\n",
            "  [2.603157   2.603157   4.41903072 4.07257871]\n",
            "  [0.         0.         0.         0.        ]]\n",
            "\n",
            " [[3.90967556 2.603157   3.75328854 3.75328854]\n",
            "  [0.         0.         0.         0.        ]\n",
            "  [4.24226949 4.603157   4.41903072 2.603157  ]\n",
            "  [0.         0.         0.         0.        ]]]\n"
          ]
        }
      ],
      "source": [
        "print(game.mat_q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6AXQlAnnEfa",
        "outputId": "0d0889a4-108e-42f2-d64f-1caff889d6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DROITE, BAS, BAS, DROITE, BAS, DROITE, fin de partie en 6 coups\n"
          ]
        }
      ],
      "source": [
        "# play a with the optimal policy\n",
        "position = (0, 0)\n",
        "for step in range(1, game.steps):\n",
        "    # play one step\n",
        "    game.mat_q, position, fin = game.oneStep(game.mat_q, position, 0, True)\n",
        "    if fin:\n",
        "        print(\"fin de partie en\", step, \"coups\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rYr5rkcnEfa",
        "outputId": "ced52dde-4305-445b-8c68-79e1dc140bda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "S (3.75  ) DROITE   | _ (3.91  ) BAS      | _ (3.75  ) GAUCHE   | _ (3.6   ) GAUCHE   | \n",
            "_______________________________________________________________________________________\n",
            "D (0.0   ) HAUT     | _ (4.07  ) BAS      | D (0.0   ) HAUT     | _ (3.46  ) HAUT     | \n",
            "_______________________________________________________________________________________\n",
            "_ (4.07  ) DROITE   | _ (4.24  ) DROITE   | _ (4.42  ) BAS      | D (0.0   ) HAUT     | \n",
            "_______________________________________________________________________________________\n",
            "_ (3.91  ) HAUT     | D (0.0   ) HAUT     | _ (4.6   ) DROITE   | J (0.0   ) HAUT     | \n",
            "_______________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "print_mat_q(game.mat_q, game.space)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vs_2S4EjiZ3"
      },
      "source": [
        "#### Analyser la table obtenue, montrer par simulation que votre politique ainsi définie fonctionne\n",
        "\n",
        "Dans la table obtenue, chaque ligne represente une case du plateau, une ligne est de la forme [recompense en allant en ***HAUT***, recompense en allant à ***GAUCHE***, recompense en allant en ***BAS***,  recompense en allant à ***DROITE***].\n",
        "\n",
        "Nous pouvons voir que dans chaque ligne, la recompense maximale est associée à la direction qui permet de gagner la partie. Ce qui signifie que notre politique est correcte.\n",
        "\n",
        "Notre simulation montre que notre politique fonctionne, car l'agent arrive à la case d'arrivée en 6 coups, ce qui est le nombre de coups minimum pour gagner la partie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIwfF1StjiZ3"
      },
      "source": [
        "### Test avec différents paramètres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PErqn7f2jiZ4"
      },
      "outputs": [],
      "source": [
        "def play_with_rewards(start_reward, dragon_reward, empty_reward, jail_reward):\n",
        "    # set the rewards\n",
        "    Rewards.set_rewards({\"S\": start_reward, \"D\": dragon_reward, \"J\": jail_reward, \"_\": empty_reward})\n",
        "\n",
        "    # play\n",
        "    game = Game()\n",
        "    game.apply_algorithm()\n",
        "    game.play()\n",
        "    print_mat_q(game.mat_q, game.space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "#play_with_rewards(0, -1, -0.1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "#play_with_rewards(0, -1, -0.1, -10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "#play_with_rewards(0, -1, -0.1, -100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "#play_with_rewards(0, -1, -0.1, -100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_XvbUyvnEfa"
      },
      "source": [
        "# Deep Q-Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "SQdRhWhsnEfb"
      },
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "import tensorflow as tf\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "TO9tRtzvjiZ4"
      },
      "outputs": [],
      "source": [
        "# configuration\n",
        "GAMMA = 0.999\n",
        "ALPHA = 0.81"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcaCB4TPnEfb"
      },
      "source": [
        "##### Test avec une structure 2 couches denses ayant 16 entrées (nombre de cases) et 4 sorties (4 actions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "rXv4ZhrfnEfb"
      },
      "outputs": [],
      "source": [
        "# a class for the game\n",
        "class DeepGame:\n",
        "    # constructor that takes :\n",
        "    # number of episodes : 10000 by default\n",
        "    # number of steps : 100 by default\n",
        "    # is_random_space : False by default\n",
        "    # vec_etat : vector of states (for deep Q learning)\n",
        "    # a model : CNN\n",
        "    # the optimizer name\n",
        "    # the loss function name\n",
        "    # verbose : False by default\n",
        "    def __init__(\n",
        "        self, \n",
        "        episodes = 10000, \n",
        "        steps = 100, \n",
        "        is_random_space = False, \n",
        "        vec_etat = None, \n",
        "        model = None,\n",
        "        optimizer_name = \"Nadam\",\n",
        "        loss_fn_name = None,\n",
        "        verbose = False\n",
        "        ):\n",
        "\n",
        "        self.episodes = episodes\n",
        "        self.steps = steps\n",
        "        self.vec_etat = vec_etat\n",
        "        self.model = model\n",
        "        self.optimizer_name = optimizer_name\n",
        "        self.loss_fn_name = loss_fn_name\n",
        "        self.verbose = verbose\n",
        "\n",
        "        # the space\n",
        "        if is_random_space:\n",
        "            self.space = get_random_space(4, 4, 3)\n",
        "        else:\n",
        "            self.space = get_default_space()\n",
        "\n",
        "        # the vector of states\n",
        "        if vec_etat is None:\n",
        "            self.set_default_vec_etat()\n",
        "\n",
        "        # the model\n",
        "        if model is None:\n",
        "            self.set_default_model()\n",
        "\n",
        "        # the optimizer\n",
        "        self.set_optimizer(optimizer_name)\n",
        "\n",
        "        # the loss function\n",
        "        self.set_loss_fn(loss_fn_name)\n",
        "\n",
        "\n",
        "\n",
        "    # a method to set the vector of states\n",
        "    def set_vec_etat(self, vec_etat):\n",
        "        self.vec_etat = vec_etat\n",
        "\n",
        "    # a method to set the default vector of states\n",
        "    def set_default_vec_etat(self):\n",
        "        self.vec_etat = np.zeros((1, get_size(self.space)))\n",
        "        self.vec_etat[0][0] = 1\n",
        "\n",
        "    # a method to reset the vector of states\n",
        "    def reset_vec_etat(self):\n",
        "        self.vec_etat = np.zeros((1, get_size(self.space)))\n",
        "\n",
        "    # a method to update the vector of states\n",
        "    def update_vec_etat(self, state):\n",
        "        self.reset_vec_etat()\n",
        "        self.vec_etat[0, int(get_lines_size(self.space) * state[0] + state[1])] = 1\n",
        "\n",
        "    # a method to set the model\n",
        "    def set_model(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    # a method to set the default model\n",
        "    def set_default_model(self):\n",
        "        self.model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Dense(4, activation='relu', input_shape=[get_size(self.space)]),\n",
        "            tf.keras.layers.Dense(4, activation='relu'),\n",
        "            tf.keras.layers.Dense(4),\n",
        "        ])\n",
        "\n",
        "    # a method to save the model\n",
        "    def save_model(self):\n",
        "\n",
        "        # number of epochs\n",
        "        E = \"E_\" + str(self.episodes)\n",
        "        # number of steps\n",
        "        S = \"_S_\" + str(self.steps)\n",
        "        # optimizer\n",
        "        O = \"_O_\" + str(self.optimizer_name)\n",
        "        # loss function\n",
        "        L = \"_L_\" + str(self.loss_fn_name)\n",
        "        # dragon reward\n",
        "        DR = \"_DR_\" + str(Rewards.rewards[\"D\"])\n",
        "        # empty reward\n",
        "        ER = \"_ER_\" + str(Rewards.rewards[\"_\"])\n",
        "        # jail reward\n",
        "        JR = \"_JR_\" + str(Rewards.rewards[\"J\"])\n",
        "\n",
        "        # file path\n",
        "        path = \"./seved_models/\" + E + S + O + L + DR + ER + JR + \".h5\"\n",
        "\n",
        "        self.model.save(path)\n",
        "\n",
        "    # a method to set the optimizer\n",
        "    # optimizer_name : Nadam by default, SGD,Adam\n",
        "    def set_optimizer(self, optimizer_name):\n",
        "        # set the optimizer according to the name \n",
        "        if optimizer_name == \"Adam\":\n",
        "            self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "        elif optimizer_name == \"SGD\":\n",
        "            self.optimizer = tf.keras.optimizers.SGD(learning_rate=0.00001)\n",
        "        else:\n",
        "            self.optimizer = tf.keras.optimizers.Nadam(learning_rate=0.00001)\n",
        "\n",
        "    # a method to set the loss function\n",
        "    # loss_fn : MSE by default, MAE\n",
        "    def set_loss_fn(self, loss_fn):\n",
        "        # set the loss function according to the name\n",
        "        if loss_fn == \"MAE\":\n",
        "            self.loss_fn = tf.keras.losses.MAE\n",
        "        else:\n",
        "            self.loss_fn = tf.keras.losses.mean_squared_error\n",
        "\n",
        "    # function to print if verbose\n",
        "    def print(self, *args):\n",
        "        if self.verbose:\n",
        "            print(*args)\n",
        "\n",
        "    # a method to show progress\n",
        "    def show_progress(self, episode, step, is_random, action, current_case, reward, next_Q_max, target):\n",
        "        choice = \"  (random)  \" if is_random else \"  (predict) \"\n",
        "\n",
        "        self.print(\n",
        "            \"episode : \" + str(episode).ljust(5) +\n",
        "            \"| step : \" + str(step).ljust(5) +\n",
        "            \"| action : \" + str(action).ljust(7) + choice +\n",
        "            \"| current_case : \" + str(current_case).ljust(3) +\n",
        "            \"| reward : \" + str(reward).ljust(5) +\n",
        "            \"| next_Q_max : \" + str(next_Q_max).ljust(15) +\n",
        "            \"| target : \" + str(target).ljust(15)\n",
        "        )\n",
        "        \n",
        "\n",
        "    #####################################################################################################################\n",
        "\n",
        "\n",
        "    # a method to choose an action with the epsilon greedy policy\n",
        "    def choose_action(self, state, epsilon):\n",
        "        is_random = np.random.uniform() < epsilon\n",
        "        if is_random:\n",
        "            action = Directions.get_random_direction()\n",
        "        else:\n",
        "            Sortie_Q = self.model(self.vec_etat)  # En entrée le vecteur symbolisant l'état\n",
        "            action = Directions.directions[np.argmax(Sortie_Q)] #On sélectionne l'action associée avec la sortie max\n",
        "        return action, is_random\n",
        "     \n",
        "    # Train the model\n",
        "    def train(self):\n",
        "        # create a stable model\n",
        "        model_stable = tf.keras.models.clone_model(self.model)\n",
        "        model_stable.set_weights(self.model.get_weights())\n",
        "\n",
        "        history = np.zeros(self.episodes)\n",
        "\n",
        "        for episode in range(self.episodes):\n",
        "            print(\"ep :\", episode)\n",
        "            # reset the position\n",
        "            position = (0, 0)\n",
        "            # calculate the epsilon\n",
        "            epsilon = self.episodes / (self.episodes + episode)\n",
        "            loss = 0\n",
        "\n",
        "            for step in range(self.steps):\n",
        "                # play one step\n",
        "                # choose an action\n",
        "                action, is_random = self.choose_action(position, epsilon)\n",
        "                # apply the action\n",
        "                position, reward, fin = applicaion_action(action, position, self.space, self.verbose)\n",
        "  \n",
        "                if fin:\n",
        "                    break\n",
        "\n",
        "                # set weights of the stable model\n",
        "                if step % 10 == 0:\n",
        "                    model_stable.set_weights(self.model.get_weights())\n",
        "\n",
        "                vec_etat_next = np.zeros((1, get_size(self.space))) # ca sera l'entree du reseau\n",
        "                vec_etat_next[0, int(get_lines_size(self.space) * position[0] + position[1])] = 1\n",
        "\n",
        "                # model stable predict\n",
        "                next_Q = model_stable.predict(vec_etat_next, verbose=0)\n",
        "                next_Q_max = np.max(next_Q)\n",
        "\n",
        "                # target\n",
        "                target = reward + GAMMA * next_Q_max * (1 - fin)\n",
        "                self.show_progress(episode, step, is_random, action, self.space[position[0]][position[1]], reward, next_Q_max, target)\n",
        "\n",
        "                # gradient descent\n",
        "                with tf.GradientTape() as tape:\n",
        "                    predict = self.model(self.vec_etat) # ce que l'on pense obtenir\n",
        "                    # get index of the action\n",
        "                    action_index = Directions.get_index(action)\n",
        "                    mask = tf.one_hot(action_index, Directions.get_size())\n",
        "                    val_predict = tf.reduce_sum(predict * mask, axis=1)\n",
        "                    loss += self.loss_fn(target, val_predict)\n",
        "\n",
        "                gradients = tape.gradient(loss, self.model.trainable_variables) # calcul du gradient de la focntion loss en fonction des variables du modèle \n",
        "                self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables)) # optimisation des paramètres du modèle\n",
        "                history[episode] = loss.numpy() # on récupère la valeur pour afficher l'évolution de l'erreur\n",
        "\n",
        "                # update the vector of states\n",
        "                self.update_vec_etat(position)\n",
        "\n",
        "        plt.plot(history, color=\"red\")\n",
        "        plt.title(\"Evolution de l'erreur\")\n",
        "        plt.show()\n",
        "\n",
        "        # save the model\n",
        "        self.save_model()\n",
        "\n",
        "    # play the game\n",
        "    def play(self):\n",
        "\n",
        "        iter = 0\n",
        "        position = (0, 0)\n",
        "        fin = False\n",
        "\n",
        "        while iter < self.steps and not fin:\n",
        "            iter += 1\n",
        "            # update the vector of states\n",
        "            self.update_vec_etat(position)\n",
        "            # choose an action\n",
        "            action, _ = self.choose_action(position, 0)\n",
        "            # apply the action\n",
        "            new_position, reward, fin = applicaion_action(action, position, self.space)\n",
        "\n",
        "            print( str(position) + \" \" + str(action) + \" \" + str(new_position))\n",
        "            \n",
        "            if fin:\n",
        "                print(\"fin de partie en\", iter, \"coups\")\n",
        "                break\n",
        "            # update the position\n",
        "            position = new_position\n",
        "\n",
        "        if iter == self.steps:\n",
        "            print(\"Trop d'itérations\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "p6GfYriK4m1A"
      },
      "outputs": [],
      "source": [
        "# function to create a game with a configuration train and play\n",
        "def create_game(optimizer_name, loss_fn_name, episodes, steps, dragon_reward, jail_reward, empty_reward, start_reward=-5, verbose=False):\n",
        "    # set the rewards\n",
        "    Rewards.set_rewards({\"S\": start_reward, \"D\": dragon_reward, \"J\": jail_reward, \"_\": empty_reward})\n",
        "    # create the game\n",
        "    game = DeepGame(episodes=episodes, steps=steps, optimizer_name=optimizer_name, loss_fn_name=loss_fn_name, verbose=verbose)\n",
        "\n",
        "    game.train()\n",
        "    game.play()\n",
        "\n",
        "    return game"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w0TgfG6B6UVS"
      },
      "source": [
        "#### TEST\n",
        "\n",
        "*   ***optimizer*** : Adam\n",
        "*   ***loss function*** : MAE\n",
        "*   ***epochs*** : 1000\n",
        "*   ***steps*** : 100\n",
        "*   ***Reward Dragon*** : -500\n",
        "*   ***Reward Empty*** : -20\n",
        "*   ***Reward Jail*** : 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C9ocj0r97kU8",
        "outputId": "3feb6d94-4353-467e-d91d-b313068c01b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep : 0\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 1\n",
            "episode : 1    | step : 0    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04755603     | target : -4.952491524536162\n",
            "episode : 1    | step : 1    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06559524     | target : 0.06552964416146279\n",
            "episode : 1    | step : 2    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04755603     | target : -4.952491524536162\n",
            "episode : 1    | step : 3    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04755603     | target : -4.952491524536162\n",
            "episode : 1    | step : 4    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04755603     | target : -4.952491524536162\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 2\n",
            "episode : 2    | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047555435    | target : -4.952492119986564\n",
            "episode : 2    | step : 1    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047555435    | target : -4.952492119986564\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 3\n",
            "episode : 3    | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.065599374    | target : 0.06553377509862185\n",
            "episode : 3    | step : 1    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047579423    | target : -4.952468156829476\n",
            "episode : 3    | step : 2    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047579423    | target : -4.952468156829476\n",
            "episode : 3    | step : 3    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.065599374    | target : 0.06553377509862185\n",
            "episode : 3    | step : 4    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.065599374    | target : 0.06553377509862185\n",
            "episode : 3    | step : 5    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.065599374    | target : 0.06553377509862185\n",
            "episode : 3    | step : 6    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.10695092     | target : 0.10684396543353795\n",
            "episode : 3    | step : 7    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.107791595    | target : 0.10768380356580019\n",
            "episode : 3    | step : 8    | action : GAUCHE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.058268845    | target : 0.058210576236248014\n",
            "episode : 3    | step : 9    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.07560131     | target : 0.07552570822834968\n",
            "episode : 3    | step : 10   | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.058342174    | target : 0.0582838315218687\n",
            "episode : 3    | step : 11   | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.07554576     | target : 0.07547021225094795\n",
            "episode : 3    | step : 12   | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.07554576     | target : 0.07547021225094795\n",
            "episode : 3    | step : 13   | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.058342174    | target : 0.0582838315218687\n",
            "episode : 3    | step : 14   | action : GAUCHE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.058342174    | target : 0.0582838315218687\n",
            "episode : 3    | step : 15   | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.10781858     | target : 0.10771076258271933\n",
            "episode : 3    | step : 16   | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.104506925    | target : 0.1044024178236723\n",
            "episode : 3    | step : 17   | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.015120229    | target : 0.015105108523741365\n",
            "\u001b[92m***********************************************************************************************************************************************************\n",
            "********************************************************************** YOU WIN ****************************************************************************\n",
            "***********************************************************************************************************************************************************\n",
            "\u001b[0m\n",
            "ep : 4\n",
            "episode : 4    | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.065699734    | target : 0.06563403405994177\n",
            "episode : 4    | step : 1    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.065699734    | target : 0.06563403405994177\n",
            "episode : 4    | step : 2    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047655113    | target : -4.952392542071641\n",
            "episode : 4    | step : 3    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.065699734    | target : 0.06563403405994177\n",
            "episode : 4    | step : 4    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10700742     | target : 0.10690041413158179\n",
            "episode : 4    | step : 5    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.065699734    | target : 0.06563403405994177\n",
            "episode : 4    | step : 6    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047655113    | target : -4.952392542071641\n",
            "episode : 4    | step : 7    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047655113    | target : -4.952392542071641\n",
            "episode : 4    | step : 8    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047655113    | target : -4.952392542071641\n",
            "episode : 4    | step : 9    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047655113    | target : -4.952392542071641\n",
            "episode : 4    | step : 10   | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04767957     | target : -4.952368109997362\n",
            "episode : 4    | step : 11   | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06574512     | target : 0.06567937760800123\n",
            "episode : 4    | step : 12   | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04767957     | target : -4.952368109997362\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 5\n",
            "episode : 5    | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06575676     | target : 0.06569100377708674\n",
            "episode : 5    | step : 1    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.10704371     | target : 0.1069366696178913\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 6\n",
            "episode : 6    | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047694776    | target : -4.952352918568999\n",
            "episode : 6    | step : 1    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047694776    | target : -4.952352918568999\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 7\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 8\n",
            "episode : 8    | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06577266     | target : 0.06570688741654157\n",
            "episode : 8    | step : 1    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.012396169    | target : 0.012383772726170719\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 9\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 10\n",
            "episode : 10   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047726534    | target : -4.952321192227304\n",
            "episode : 10   | step : 1    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047726534    | target : -4.952321192227304\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 11\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 12\n",
            "episode : 12   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047737744    | target : -4.9523099940381945\n",
            "episode : 12   | step : 1    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047737744    | target : -4.9523099940381945\n",
            "episode : 12   | step : 2    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.065771505    | target : 0.06570573373138905\n",
            "episode : 12   | step : 3    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.106874146    | target : 0.10676727142184973\n",
            "episode : 12   | step : 4    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.065771505    | target : 0.06570573373138905\n",
            "episode : 12   | step : 5    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047737744    | target : -4.9523099940381945\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 13\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 14\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 15\n",
            "episode : 15   | step : 0    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047780074    | target : -4.952267705895006\n",
            "episode : 15   | step : 1    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.065803066    | target : 0.06573726283013821\n",
            "episode : 15   | step : 2    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.0123283705   | target : 0.012316042103804648\n",
            "episode : 15   | step : 3    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.11115551     | target : 0.11104435443878174\n",
            "episode : 15   | step : 4    | action : GAUCHE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.0123283705   | target : 0.012316042103804648\n",
            "episode : 15   | step : 5    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.0123283705   | target : 0.012316042103804648\n",
            "episode : 15   | step : 6    | action : GAUCHE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.065803066    | target : 0.06573726283013821\n",
            "episode : 15   | step : 7    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.10684342     | target : 0.1067365759536624\n",
            "episode : 15   | step : 8    | action : HAUT     (predict) | current_case : _  | reward : 0    | next_Q_max : 0.065803066    | target : 0.06573726283013821\n",
            "episode : 15   | step : 9    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047780074    | target : -4.952267705895006\n",
            "episode : 15   | step : 10   | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047809154    | target : -4.952238655358553\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 16\n",
            "episode : 16   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04780847     | target : -4.952239340126514\n",
            "episode : 16   | step : 1    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04780847     | target : -4.952239340126514\n",
            "episode : 16   | step : 2    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04780847     | target : -4.952239340126514\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 17\n",
            "episode : 17   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04782618     | target : -4.952221647806466\n",
            "episode : 17   | step : 1    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04782618     | target : -4.952221647806466\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 18\n",
            "episode : 18   | step : 0    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04786126     | target : -4.9521866018287835\n",
            "episode : 18   | step : 1    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04786126     | target : -4.9521866018287835\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 19\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 20\n",
            "episode : 20   | step : 0    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04786276     | target : -4.952185102038086\n",
            "episode : 20   | step : 1    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06584959     | target : 0.06578373773396015\n",
            "episode : 20   | step : 2    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10678813     | target : 0.10668134048581124\n",
            "episode : 20   | step : 3    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06584959     | target : 0.06578373773396015\n",
            "episode : 20   | step : 4    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04786276     | target : -4.952185102038086\n",
            "episode : 20   | step : 5    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04786276     | target : -4.952185102038086\n",
            "episode : 20   | step : 6    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04786276     | target : -4.952185102038086\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 21\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 22\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 23\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 24\n",
            "episode : 24   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.0658862      | target : 0.06582031327486038\n",
            "episode : 24   | step : 1    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.0658862      | target : 0.06582031327486038\n",
            "episode : 24   | step : 2    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.106782906    | target : 0.10667612285166979\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 25\n",
            "episode : 25   | step : 0    | action : HAUT     (predict) | current_case : S  | reward : -5   | next_Q_max : 0.047927685    | target : -4.952120242603123\n",
            "episode : 25   | step : 1    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047927685    | target : -4.952120242603123\n",
            "episode : 25   | step : 2    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06591134     | target : 0.06584542639553546\n",
            "episode : 25   | step : 3    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.012028803    | target : 0.012016774314455688\n",
            "episode : 25   | step : 4    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.11071687     | target : 0.11060615504533053\n",
            "episode : 25   | step : 5    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.0005053191   | target : 0.0005048137789126486\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 26\n",
            "episode : 26   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047941197    | target : -4.952106744486839\n",
            "episode : 26   | step : 1    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.047941197    | target : -4.952106744486839\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 27\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 28\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 29\n",
            "episode : 29   | step : 0    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04796445     | target : -4.9520835144780575\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 30\n",
            "episode : 30   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06586814     | target : 0.0658022711277008\n",
            "episode : 30   | step : 1    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06586814     | target : 0.0658022711277008\n",
            "episode : 30   | step : 2    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.01201321     | target : 0.012001196773722769\n",
            "episode : 30   | step : 3    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.01201321     | target : 0.012001196773722769\n",
            "episode : 30   | step : 4    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.11075207     | target : 0.11064131639152765\n",
            "episode : 30   | step : 5    | action : GAUCHE   (predict) | current_case : _  | reward : 0    | next_Q_max : 0.01201321     | target : 0.012001196773722769\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 31\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 32\n",
            "episode : 32   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.0658615      | target : 0.06579563929885626\n",
            "episode : 32   | step : 1    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.10654393     | target : 0.1064373844563961\n",
            "episode : 32   | step : 2    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.107629456    | target : 0.10752182617038489\n",
            "episode : 32   | step : 3    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.10529881     | target : 0.1051935108974576\n",
            "episode : 32   | step : 4    | action : GAUCHE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.107629456    | target : 0.10752182617038489\n",
            "episode : 32   | step : 5    | action : GAUCHE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.05847223     | target : 0.05841375879943371\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 33\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 34\n",
            "episode : 34   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06589819     | target : 0.06583228927105665\n",
            "episode : 34   | step : 1    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.01199888     | target : 0.011986880843527616\n",
            "episode : 34   | step : 2    | action : GAUCHE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06589819     | target : 0.06583228927105665\n",
            "episode : 34   | step : 3    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06589819     | target : 0.06583228927105665\n",
            "episode : 34   | step : 4    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048008133    | target : -4.952039875406772\n",
            "episode : 34   | step : 5    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06589819     | target : 0.06583228927105665\n",
            "episode : 34   | step : 6    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.01199888     | target : 0.011986880843527616\n",
            "episode : 34   | step : 7    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.11070218     | target : 0.11059147719293833\n",
            "episode : 34   | step : 8    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.11070218     | target : 0.11059147719293833\n",
            "episode : 34   | step : 9    | action : GAUCHE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.01199888     | target : 0.011986880843527616\n",
            "episode : 34   | step : 10   | action : GAUCHE   (predict) | current_case : _  | reward : 0    | next_Q_max : 0.06591936     | target : 0.06585344264656305\n",
            "episode : 34   | step : 11   | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048017293    | target : -4.9520307240784165\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 35\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 36\n",
            "episode : 36   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06593114     | target : 0.06586521023511886\n",
            "episode : 36   | step : 1    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06593114     | target : 0.06586521023511886\n",
            "episode : 36   | step : 2    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06593114     | target : 0.06586521023511886\n",
            "episode : 36   | step : 3    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10657181     | target : 0.1064652366489172\n",
            "episode : 36   | step : 4    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06593114     | target : 0.06586521023511886\n",
            "episode : 36   | step : 5    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10657181     | target : 0.1064652366489172\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 37\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 38\n",
            "episode : 38   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04805166     | target : -4.951996392641217\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 39\n",
            "episode : 39   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04805952     | target : -4.951988540139049\n",
            "episode : 39   | step : 1    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04805952     | target : -4.951988540139049\n",
            "episode : 39   | step : 2    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.065971985    | target : 0.06590601347386837\n",
            "episode : 39   | step : 3    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.01191353     | target : 0.011901616067625582\n",
            "episode : 39   | step : 4    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.11049579     | target : 0.11038529504835605\n",
            "episode : 39   | step : 5    | action : GAUCHE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.01191353     | target : 0.011901616067625582\n",
            "episode : 39   | step : 6    | action : GAUCHE   (predict) | current_case : _  | reward : 0    | next_Q_max : 0.065971985    | target : 0.06590601347386837\n",
            "episode : 39   | step : 7    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.10648913     | target : 0.10638264023512602\n",
            "episode : 39   | step : 8    | action : HAUT     (predict) | current_case : _  | reward : 0    | next_Q_max : 0.065971985    | target : 0.06590601347386837\n",
            "episode : 39   | step : 9    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.10648913     | target : 0.10638264023512602\n",
            "episode : 39   | step : 10   | action : HAUT     (predict) | current_case : _  | reward : 0    | next_Q_max : 0.06602855     | target : 0.06596252171695233\n",
            "episode : 39   | step : 11   | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048153646    | target : -4.951894507355988\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 40\n",
            "episode : 40   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048158634    | target : -4.951889524180442\n",
            "episode : 40   | step : 1    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048158634    | target : -4.951889524180442\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 41\n",
            "episode : 41   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06605204     | target : 0.0659859899058938\n",
            "episode : 41   | step : 1    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.10636111     | target : 0.10625475237518549\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 42\n",
            "episode : 42   | step : 0    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04822051     | target : -4.951827708985657\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 43\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 44\n",
            "episode : 44   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06608628     | target : 0.06602019108831883\n",
            "episode : 44   | step : 1    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.011833463    | target : 0.011821629401296377\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 45\n",
            "episode : 45   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06609316     | target : 0.06602706854045391\n",
            "episode : 45   | step : 1    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10641418     | target : 0.10630776234716177\n",
            "episode : 45   | step : 2    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.1075632      | target : 0.10745563441514969\n",
            "episode : 45   | step : 3    | action : GAUCHE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.058661122    | target : 0.05860246075317264\n",
            "episode : 45   | step : 4    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.07479577     | target : 0.07472097189724446\n",
            "episode : 45   | step : 5    | action : GAUCHE   (predict) | current_case : _  | reward : 0    | next_Q_max : 0.07479577     | target : 0.07472097189724446\n",
            "episode : 45   | step : 6    | action : GAUCHE   (predict) | current_case : _  | reward : 0    | next_Q_max : 0.07479577     | target : 0.07472097189724446\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 46\n",
            "episode : 46   | step : 0    | action : GAUCHE   (predict) | current_case : S  | reward : -5   | next_Q_max : 0.04828145     | target : -4.951766831625253\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 47\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 48\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 49\n",
            "episode : 49   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06615517     | target : 0.0660890177115798\n",
            "episode : 49   | step : 1    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04828065     | target : -4.951767631761729\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 50\n",
            "episode : 50   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06617018     | target : 0.06610400817543269\n",
            "episode : 50   | step : 1    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.011889841    | target : 0.011877951566129924\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 51\n",
            "episode : 51   | step : 0    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048286706    | target : -4.951761580497027\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 52\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 53\n",
            "episode : 53   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06617877     | target : 0.0661125901043415\n",
            "episode : 53   | step : 1    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10646554     | target : 0.10635907528549433\n",
            "episode : 53   | step : 2    | action : HAUT     (predict) | current_case : _  | reward : 0    | next_Q_max : 0.06617877     | target : 0.0661125901043415\n",
            "episode : 53   | step : 3    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10646554     | target : 0.10635907528549433\n",
            "episode : 53   | step : 4    | action : HAUT     (predict) | current_case : _  | reward : 0    | next_Q_max : 0.06617877     | target : 0.0661125901043415\n",
            "episode : 53   | step : 5    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06617877     | target : 0.0661125901043415\n",
            "episode : 53   | step : 6    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.011888085    | target : 0.011876196848228575\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 54\n",
            "episode : 54   | step : 0    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048332524    | target : -4.951715808968991\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 55\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 56\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 57\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 58\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 59\n",
            "episode : 59   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048333965    | target : -4.951714368723333\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 60\n",
            "episode : 60   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048352133    | target : -4.951696218650788\n",
            "episode : 60   | step : 1    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048352133    | target : -4.951696218650788\n",
            "episode : 60   | step : 2    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06624341     | target : 0.06617716670036317\n",
            "episode : 60   | step : 3    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.011937268    | target : 0.011925330810248852\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 61\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 62\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 63\n",
            "episode : 63   | step : 0    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048398506    | target : -4.9516498926095665\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 64\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 65\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 66\n",
            "episode : 66   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.066255644    | target : 0.06618938831984997\n",
            "episode : 66   | step : 1    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.011961609    | target : 0.011949647516012192\n",
            "episode : 66   | step : 2    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.011961609    | target : 0.011949647516012192\n",
            "episode : 66   | step : 3    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.011961609    | target : 0.011949647516012192\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 67\n",
            "episode : 67   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048412263    | target : -4.951636148869992\n",
            "episode : 67   | step : 1    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.066260934    | target : 0.06619467294216155\n",
            "episode : 67   | step : 2    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.1064254      | target : 0.10631897170096635\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 68\n",
            "episode : 68   | step : 0    | action : HAUT     (predict) | current_case : S  | reward : -5   | next_Q_max : 0.048443086    | target : -4.951605356641114\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 69\n",
            "episode : 69   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06626922     | target : 0.06620294970273971\n",
            "episode : 69   | step : 1    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10629831     | target : 0.10619201423227786\n",
            "episode : 69   | step : 2    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.10748265     | target : 0.10737516673654318\n",
            "episode : 69   | step : 3    | action : HAUT     (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10629831     | target : 0.10619201423227786\n",
            "episode : 69   | step : 4    | action : HAUT     (predict) | current_case : _  | reward : 0    | next_Q_max : 0.06626922     | target : 0.06620294970273971\n",
            "episode : 69   | step : 5    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10629831     | target : 0.10619201423227786\n",
            "episode : 69   | step : 6    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06626922     | target : 0.06620294970273971\n",
            "episode : 69   | step : 7    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10629831     | target : 0.10619201423227786\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 70\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 71\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 72\n",
            "episode : 72   | step : 0    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04853771     | target : -4.951510828889907\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 73\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 74\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 75\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 76\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 77\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 78\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 79\n",
            "episode : 79   | step : 0    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04853463     | target : -4.951513902902603\n",
            "episode : 79   | step : 1    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.066367954    | target : 0.06630158606171609\n",
            "episode : 79   | step : 2    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10630343     | target : 0.10619712766259909\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 80\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 81\n",
            "episode : 81   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048555706    | target : -4.951492850009352\n",
            "episode : 81   | step : 1    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048555706    | target : -4.951492850009352\n",
            "episode : 81   | step : 2    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048555706    | target : -4.951492850009352\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 82\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 83\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 84\n",
            "episode : 84   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048583638    | target : -4.951464945714921\n",
            "episode : 84   | step : 1    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048583638    | target : -4.951464945714921\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 85\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 86\n",
            "episode : 86   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06639498     | target : 0.0663285822942853\n",
            "episode : 86   | step : 1    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10616547     | target : 0.10605930322408676\n",
            "episode : 86   | step : 2    | action : HAUT     (predict) | current_case : _  | reward : 0    | next_Q_max : 0.06639498     | target : 0.0663285822942853\n",
            "episode : 86   | step : 3    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10616547     | target : 0.10605930322408676\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 87\n",
            "episode : 87   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06643974     | target : 0.06637330061942338\n",
            "episode : 87   | step : 1    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048649654    | target : -4.951398995861411\n",
            "episode : 87   | step : 2    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048649654    | target : -4.951398995861411\n",
            "episode : 87   | step : 3    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048649654    | target : -4.951398995861411\n",
            "episode : 87   | step : 4    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06643974     | target : 0.06637330061942338\n",
            "episode : 87   | step : 5    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.106144905    | target : 0.10603876018524169\n",
            "episode : 87   | step : 6    | action : HAUT     (predict) | current_case : _  | reward : 0    | next_Q_max : 0.06643974     | target : 0.06637330061942338\n",
            "episode : 87   | step : 7    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.012167619    | target : 0.012155450991354884\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 88\n",
            "episode : 88   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06649534     | target : 0.06642884125560522\n",
            "episode : 88   | step : 1    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10609971     | target : 0.10599361015856266\n",
            "episode : 88   | step : 2    | action : HAUT     (predict) | current_case : _  | reward : 0    | next_Q_max : 0.06649534     | target : 0.06642884125560522\n",
            "episode : 88   | step : 3    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048727818    | target : -4.9513209099844095\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 89\n",
            "episode : 89   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04875632     | target : -4.951292436290532\n",
            "episode : 89   | step : 1    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04875632     | target : -4.951292436290532\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 90\n",
            "episode : 90   | step : 0    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.04879429     | target : -4.9512545060999695\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 91\n",
            "episode : 91   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06654554     | target : 0.06647899306565523\n",
            "episode : 91   | step : 1    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10606892     | target : 0.10596284770220518\n",
            "episode : 91   | step : 2    | action : BAS      (random)  | current_case : _  | reward : 0    | next_Q_max : 0.107340924    | target : 0.10723358351737261\n",
            "episode : 91   | step : 3    | action : HAUT     (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10606892     | target : 0.10596284770220518\n",
            "episode : 91   | step : 4    | action : HAUT     (random)  | current_case : _  | reward : 0    | next_Q_max : 0.06654554     | target : 0.06647899306565523\n",
            "episode : 91   | step : 5    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.10606892     | target : 0.10596284770220518\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 92\n",
            "episode : 92   | step : 0    | action : HAUT     (random)  | current_case : S  | reward : -5   | next_Q_max : 0.0488614      | target : -4.951187462106347\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 93\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 94\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 95\n",
            "episode : 95   | step : 0    | action : DROITE   (random)  | current_case : _  | reward : 0    | next_Q_max : 0.066607974    | target : 0.06654136649519204\n",
            "episode : 95   | step : 1    | action : BAS      (predict) | current_case : _  | reward : 0    | next_Q_max : 0.105971865    | target : 0.10586589349061251\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 96\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 97\n",
            "episode : 97   | step : 0    | action : GAUCHE   (random)  | current_case : S  | reward : -5   | next_Q_max : 0.048893563    | target : -4.951155330114067\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 98\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n",
            "ep : 99\n",
            "\u001b[91m********************************************************************** YOU LOOSE ***************************************************************************\n",
            "\u001b[0m\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "(0, 0) BAS (0, 0)\n",
            "fin de partie en 1 coups\n"
          ]
        }
      ],
      "source": [
        "#game1 = create_game(optimizer_name=\"Adam\", loss_fn_name=\"MAE\", episodes=100, steps=100, dragon_reward=-10, empty_reward=0, jail_reward=10, verbose=False)\n",
        "game1 = create_game(optimizer_name=\"Nadam\", loss_fn_name=\"MSE\", episodes=100, steps=100, dragon_reward=-1000, empty_reward=0, jail_reward=10000, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5uSY-7_7agv"
      },
      "source": [
        "#### TEST\n",
        "\n",
        "\n",
        "*   ***optimizer*** : Nadam\n",
        "*   ***loss function*** : MSE\n",
        "*   ***epochs*** : 5000\n",
        "*   ***steps*** : 100\n",
        "*   ***Reward Dragon*** : -100\n",
        "*   ***Reward Empty*** : -10\n",
        "*   ***Reward Jail*** : 1000\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_LPDJcA7c11",
        "outputId": "f7d84157-9ff3-4836-d901-10860a2812a3"
      },
      "outputs": [],
      "source": [
        "#game2 = create_game(optimizer_name=\"Nadam\", loss_fn_name=\"MSE\", episodes=3000, steps=100, dragon_reward=-100, empty_reward=-10, jail_reward=1000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "4428cbe1ba9314b3551257500664b995dcc328d303584ff4cad6f1a703111ed9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
